{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EnsembleRegressor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guOYfiPsjorc",
        "outputId": "c5963bf6-35e1-43cf-a6be-6e84b7f64c16"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-0.26-cp37-none-manylinux1_x86_64.whl (69.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 69.2 MB 8.3 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo4tHyybef0J"
      },
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.utils import resample\n",
        "from tqdm import tqdm\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression,Ridge\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fSlZ87fNikM",
        "outputId": "f2eb109c-5d6b-4a4a-c90c-f95109a5d93d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luizr2hqcr_G"
      },
      "source": [
        "#loading training data\n",
        "df = pd.read_feather('/content/drive/MyDrive/ashrae_Great_Energy_Prediction/train_feature_engineering.feather')\n",
        "df.drop('index',axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctPog4TbflBa"
      },
      "source": [
        "### Drop the features which are not important"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJR3WXID3WVi"
      },
      "source": [
        "df.drop(['site_id','timestamp','wind_speed','wind_direction','is_summer_month','dew_temperature','relative_humidity','meter_reading','sea_level_pressure','cloud_coverage','precip_depth_1_hr','busy_hours','Sensible_Heat','discomfort_index','wind_chill','month'],axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XOdPnGnf5vQ"
      },
      "source": [
        "### Hypertuning K models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37gQ1jmqg0Pg"
      },
      "source": [
        "#base models\n",
        "base_models = [LinearRegression(fit_intercept=True,normalize=True,copy_X=True),\n",
        "               RandomForestRegressor(max_depth=9,n_estimators=80,n_jobs=-1),\n",
        "               XGBRegressor(n_estimators=1500,max_depth=9,learning_rate=0.03,colsample_bytree=0.8,tree_method='gpu_hist',silent=True),\n",
        "               CatBoostRegressor(max_depth=13,n_estimators=1500,task_type='GPU',learning_rate=0.1,silent=True),\n",
        "               LGBMRegressor(n_estimators=1200,min_child_samples=100,max_depth=11,learning_rate=0.1,colsample_bytree=0.9,n_jobs=-1,silent=True),\n",
        "               Ridge(solver = \"lsqr\", fit_intercept=True,alpha = 10000)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poe7ziJJZbQN"
      },
      "source": [
        "## Considering with 100 models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39tMmCoXgFsT",
        "outputId": "546a5cd1-4858-4165-e69c-e11990265b44"
      },
      "source": [
        "#Taking a dataset of 500000 datapoints and splitting dataset into 80% training and 20% testing\n",
        "df = df[:500000]\n",
        "split_size = int(len(df)*0.8)\n",
        "train , test = df[0:split_size] , df[split_size:]\n",
        "\n",
        "#splitting training data into 50% D1 and 50% D2\n",
        "D_split_size = int(len(train)*0.5)\n",
        "D1 , D2 = train[0:D_split_size] , train[D_split_size:]\n",
        "\n",
        "D1_x = D1.drop('log_meter_reading',axis=1)\n",
        "D1_y = D1['log_meter_reading'].astype(np.float32)\n",
        "D2_x = D2.drop('log_meter_reading',axis=1)\n",
        "D2_y = D2['log_meter_reading'].astype(np.float32)\n",
        "test_x = test.drop('log_meter_reading',axis=1)\n",
        "test_y = test['log_meter_reading'].astype(np.float32)\n",
        "\n",
        "\n",
        "#From this D1, doing sampling with replacement to create d1,d2,d3....d100(100 samples).\n",
        "x_100_samples = []\n",
        "y_100_samples = []\n",
        "for i in tqdm(list(range(100))):\n",
        "    x , y = resample(D1_x,D1_y,replace=True,random_state=i,n_samples=10000)\n",
        "    x_100_samples.append(x)\n",
        "    y_100_samples.append(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 555.26it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueNgCaLNjCKR"
      },
      "source": [
        "D2_predict = []\n",
        "test_predict = []\n",
        "models = []   \n",
        "def ensemble_regressor(x,y,D2_x,test_x,model):\n",
        "    model = model.fit(x,y)\n",
        "    D2_predict.append(pd.DataFrame(model.predict(D2_x)))\n",
        "    test_predict.append(pd.DataFrame(model.predict(test_x)))\n",
        "    models.append(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zx0MjeCehZn",
        "outputId": "4fab7b3c-6c25-4eed-b1ea-2a623b98af87"
      },
      "source": [
        "for i in tqdm(list(range(100))):     \n",
        "    ensemble_regressor(x_100_samples[i],y_100_samples[i] ,D2_x,test_x  ,model = random.choice(base_models))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [20:13<00:00, 12.14s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkme0szo488Z",
        "outputId": "bec4519e-06a6-43ae-eee4-65841da533a4"
      },
      "source": [
        "#Creating a new dataset for these 100 predictions of D2\n",
        "D2_prediction = pd.DataFrame(D2_predict[0])\n",
        "for i in tqdm(list(range(99))): \n",
        "    D2_prediction = pd.concat([D2_prediction, D2_predict[i+1]], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 99/99 [00:05<00:00, 17.62it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow9hDIMe5XN_",
        "outputId": "5470055b-dd4a-4a4f-f47e-9b1304d66f10"
      },
      "source": [
        "#Creating a new dataset for these 100 predictions of test_data\n",
        "test_prediction = pd.DataFrame(test_predict[0])\n",
        "for i in tqdm(list(range(99))):\n",
        "    test_prediction = pd.concat([test_prediction, test_predict[i+1]], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 99/99 [00:03<00:00, 29.32it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiZ0os6i432w"
      },
      "source": [
        "D2_prediction.to_csv('/content/drive/MyDrive/ashrae_Great_Energy_Prediction/Ensemble_Regressor/D2_prediction_100.csv',header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89dAqsfr5geJ"
      },
      "source": [
        "test_prediction.to_csv('/content/drive/MyDrive/ashrae_Great_Energy_Prediction/Ensemble_Regressor/test_prediction_100.csv',header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2Guh7tqLFXS"
      },
      "source": [
        "D2_prediction = pd.read_csv('/content/drive/MyDrive/ashrae_Great_Energy_Prediction/Ensemble_Regressor/D2_prediction_100.csv', header=None)\n",
        "test_prediction = pd.read_csv('/content/drive/MyDrive/ashrae_Great_Energy_Prediction/Ensemble_Regressor/test_prediction_100.csv',header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU_h8azsLTFi"
      },
      "source": [
        "D2_pred = D2_prediction.values\n",
        "test_pred = test_prediction.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6uwID6vLg_g"
      },
      "source": [
        "base_models = [RandomForestRegressor(max_depth=9,n_estimators=80,n_jobs=-1),\n",
        "               XGBRegressor(n_estimators=1500,max_depth=9,learning_rate=0.03,colsample_bytree=0.8,tree_method='gpu_hist',silent=True),\n",
        "               CatBoostRegressor(max_depth=13,n_estimators=1500,task_type='GPU',learning_rate=0.1,silent=True),\n",
        "               LGBMRegressor(n_estimators=1200,min_child_samples=100,max_depth=11,learning_rate=0.1,colsample_bytree=0.9,n_jobs=-1,silent=True)]\n",
        "\n",
        "\n",
        "def best_model(base_models,D2_pred,D2_y,test_pred):\n",
        "    for clf in tqdm(base_models):\n",
        "        model = clf.fit(D2_pred,D2_y)\n",
        "        train_rmsle = np.sqrt(mean_squared_error(D2_y ,model.predict(D2_pred)))\n",
        "        test_rmsle = np.sqrt(mean_squared_error(test_y , model.predict(test_pred)))\n",
        "        print('\\nTrain_rmsle : '+str(train_rmsle)+'  Test_rmsle : '+str(test_rmsle))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGVqsTzjL2th",
        "outputId": "e8f17cc5-c5b8-477b-c99f-fac26a5242f5"
      },
      "source": [
        "best_model(base_models,D2_pred,D2_y,test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 1/4 [06:02<18:06, 362.14s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train_rmsle : 0.6133195988732062  Test_rmsle : 0.7704567825570275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 2/4 [06:40<08:49, 264.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train_rmsle : 0.16304833  Test_rmsle : 0.6615613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 3/4 [07:26<03:19, 199.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train_rmsle : 0.3385331204957171  Test_rmsle : 0.6833999892428813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [09:02<00:00, 135.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train_rmsle : 0.3406604850994118  Test_rmsle : 0.6630891887206014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUTjgZ9jZsf1"
      },
      "source": [
        "## Considering 300 models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEGJxumrc2Ll",
        "outputId": "daa40599-08d0-4eb7-a686-b8761dc4f862"
      },
      "source": [
        "#Taking a dataset of 500000 datapoints and splitting dataset into 80% training and 20% testing\n",
        "df = df[:500000]\n",
        "split_size = int(len(df)*0.8)\n",
        "train , test = df[0:split_size] , df[split_size:]\n",
        "\n",
        "#splitting training data into 50% D1 and 50% D2\n",
        "D_split_size = int(len(train)*0.5)\n",
        "D1 , D2 = train[0:D_split_size] , train[D_split_size:]\n",
        "\n",
        "D1_x = D1.drop('log_meter_reading',axis=1)\n",
        "D1_y = D1['log_meter_reading'].astype(np.float32)\n",
        "D2_x = D2.drop('log_meter_reading',axis=1)\n",
        "D2_y = D2['log_meter_reading'].astype(np.float32)\n",
        "test_x = test.drop('log_meter_reading',axis=1)\n",
        "test_y = test['log_meter_reading'].astype(np.float32)\n",
        "\n",
        "\n",
        "#From this D1, doing sampling with replacement to create d1,d2,d3....d300(300 samples).\n",
        "x_300_samples = []\n",
        "y_300_samples = []\n",
        "for i in tqdm(list(range(300))):\n",
        "    x , y = resample(D1_x,D1_y,replace=True,random_state=i,n_samples=10000)\n",
        "    x_300_samples.append(x)\n",
        "    y_300_samples.append(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 300/300 [00:00<00:00, 549.69it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cdujK-GrztH"
      },
      "source": [
        "for i in tqdm(list(range(300))):     \n",
        "    ensemble_regressor(x_300_samples[i],y_300_samples[i] ,D2_x,test_x  ,model = random.choice(base_models))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnrl257emphj",
        "outputId": "2ab0c172-5b83-4189-c4a0-66a7a590bb33"
      },
      "source": [
        "#Creating a new dataset for these 300 predictions of D2\n",
        "D2_prediction = pd.DataFrame(D2_predict[0])\n",
        "for i in tqdm(list(range(299))): \n",
        "    D2_prediction = pd.concat([D2_prediction, D2_predict[i+1]], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 299/299 [01:05<00:00,  4.57it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQa2TMsWmxev",
        "outputId": "fdd24182-09ef-46b5-9e5c-1035a49a3f16"
      },
      "source": [
        "#Creating a new dataset for these 300 predictions of test_data\n",
        "test_prediction = pd.DataFrame(test_predict[0])\n",
        "for i in tqdm(list(range(299))):\n",
        "    test_prediction = pd.concat([test_prediction, test_predict[i+1]], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 299/299 [00:36<00:00,  8.23it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o9-bIzOnMiV"
      },
      "source": [
        "D2_prediction.to_csv('/content/drive/MyDrive/ashrae_Great_Energy_Prediction/Ensemble_Regressor/D2_prediction_300.csv',header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISgpSXT0nQ6R"
      },
      "source": [
        "test_prediction.to_csv('/content/drive/MyDrive/ashrae_Great_Energy_Prediction/Ensemble_Regressor/test_prediction_300.csv',header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpYaj2T8PFkz"
      },
      "source": [
        "D2_prediction = pd.read_csv('/content/drive/MyDrive/ashrae_Great_Energy_Prediction/Ensemble_Regressor/D2_prediction_300.csv', header=None)\n",
        "test_prediction = pd.read_csv('/content/drive/MyDrive/ashrae_Great_Energy_Prediction/Ensemble_Regressor/test_prediction_3 00.csv',header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfDrIWVSPJuP"
      },
      "source": [
        "D2_pred = D2_prediction.values\n",
        "test_pred = test_prediction.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1s-7t2lPbmv",
        "outputId": "30db91ef-c89d-4b6d-8985-6918b5638542"
      },
      "source": [
        "best_model(base_models,D2_pred,D2_y,test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 1/4 [18:21<55:05, 1101.84s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train_rmsle : 0.5732932979856016  Test_rmsle : 0.7466561663273591\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 2/4 [19:18<26:16, 788.37s/it] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train_rmsle : 0.13176973  Test_rmsle : 0.6440852\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 3/4 [20:50<09:39, 579.47s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train_rmsle : 0.37637886100006446  Test_rmsle : 0.6870980567884488\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [25:09<00:00, 377.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train_rmsle : 0.30131019195602926  Test_rmsle : 0.6481653139252237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6zWvnokZ0aM"
      },
      "source": [
        "## Considering with 500 models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABuAdLZDc7Q9",
        "outputId": "d27305b6-0761-4f14-c763-3ac66b198689"
      },
      "source": [
        "#Taking a dataset of 500000 datapoints and splitting dataset into 80% training and 20% testing\n",
        "df = df[:500000]\n",
        "split_size = int(len(df)*0.8)\n",
        "train , test = df[0:split_size] , df[split_size:]\n",
        "\n",
        "#splitting training data into 50% D1 and 50% D2\n",
        "D_split_size = int(len(train)*0.5)\n",
        "D1 , D2 = train[0:D_split_size] , train[D_split_size:]\n",
        "\n",
        "D1_x = D1.drop('log_meter_reading',axis=1)\n",
        "D1_y = D1['log_meter_reading'].astype(np.float32)\n",
        "D2_x = D2.drop('log_meter_reading',axis=1)\n",
        "D2_y = D2['log_meter_reading'].astype(np.float32)\n",
        "test_x = test.drop('log_meter_reading',axis=1)\n",
        "test_y = test['log_meter_reading'].astype(np.float32)\n",
        "\n",
        "\n",
        "#From this D1, doing sampling with replacement to create d1,d2,d3....d500(500 samples).\n",
        "x_500_samples = []\n",
        "y_500_samples = []\n",
        "for i in tqdm(list(range(500))):\n",
        "    x , y = resample(D1_x,D1_y,replace=True,random_state=i,n_samples=10000)\n",
        "    x_500_samples.append(x)\n",
        "    y_500_samples.append(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:00<00:00, 594.47it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eg6P99ok5Ul",
        "outputId": "ffc3ee39-b477-46f5-eab9-454226869b3b"
      },
      "source": [
        "for i in tqdm(list(range(500))):   \n",
        "    ensemble_regressor(x_500_samples[i],y_500_samples[i] ,D2_x,test_x  ,model = random.choice(base_models))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [1:45:58<00:00, 12.72s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p88agRQRkCSW",
        "outputId": "4d395168-2506-4003-9607-b69898955c4f"
      },
      "source": [
        "#Creating a new dataset for these 500 predictions of D2\n",
        "D2_prediction = pd.DataFrame(D2_predict[0])\n",
        "for i in tqdm(list(range(499))): \n",
        "    D2_prediction = pd.concat([D2_prediction, D2_predict[i+1]], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 499/499 [03:25<00:00,  2.43it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyGe5sAbkY9V",
        "outputId": "23de232d-ae5f-4cf8-ccf0-7ef5edbcbcee"
      },
      "source": [
        "#Creating a new dataset for these 500 predictions of test_data\n",
        "test_prediction = pd.DataFrame(test_predict[0])\n",
        "for i in tqdm(list(range(499))):\n",
        "    test_prediction = pd.concat([test_prediction, test_predict[i+1]], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 499/499 [01:42<00:00,  4.88it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UoHjBOu5FgN"
      },
      "source": [
        "D2_prediction.to_csv('/content/drive/MyDrive/ashrae_Great_Energy_Prediction/Ensemble_Regressor/D2_prediction.csv',header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCOAGEZs54wr"
      },
      "source": [
        "test_prediction.to_csv('/content/drive/MyDrive/ashrae_Great_Energy_Prediction/Ensemble_Regressor/test_prediction.csv',header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8HLIF4rN5ys"
      },
      "source": [
        "D2_prediction = pd.read_csv('/content/drive/MyDrive/ashrae_Great_Energy_Prediction/Ensemble_Regressor/D2_prediction.csv', header=None)\n",
        "test_prediction = pd.read_csv('/content/drive/MyDrive/ashrae_Great_Energy_Prediction/Ensemble_Regressor/test_prediction.csv',header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMNub6FmG_Lw"
      },
      "source": [
        "test_pred = test_prediction.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlsD7Q2bHfxf"
      },
      "source": [
        "D2_pred = D2_prediction.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP4myhflved9"
      },
      "source": [
        "#finding best_model for meta_model\n",
        "base_models = [RandomForestRegressor(max_depth=9,n_estimators=80,n_jobs=-1),\n",
        "               XGBRegressor(n_estimators=1500,max_depth=9,learning_rate=0.03,colsample_bytree=0.8,tree_method='gpu_hist',silent=True),\n",
        "               CatBoostRegressor(max_depth=13,n_estimators=1500,task_type='GPU',learning_rate=0.1,silent=True),\n",
        "               LGBMRegressor(n_estimators=1200,min_child_samples=100,max_depth=11,learning_rate=0.1,colsample_bytree=0.9,n_jobs=-1,silent=True)]\n",
        "\n",
        "\n",
        "def best_model(base_models,D2_pred,D2_y,test_pred):\n",
        "    for clf in tqdm(base_models):\n",
        "        model = clf.fit(D2_pred,D2_y)\n",
        "        train_rmsle = np.sqrt(mean_squared_error(D2_y ,model.predict(D2_pred)))\n",
        "        test_rmsle = np.sqrt(mean_squared_error(test_y , model.predict(test_pred)))\n",
        "        print('\\nTrain_rmsle : '+str(train_rmsle)+'  Test_rmsle : '+str(test_rmsle))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38iQLaFzyAS_",
        "outputId": "f78d946b-87b8-48ac-c72c-ca540fcd09a1"
      },
      "source": [
        "best_model(base_models,D2_pred,D2_y,test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 1/4 [29:55<1:29:45, 1795.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train_rmsle : 0.5623341999136532  Test_rmsle : 0.7417063161225945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 2/4 [31:14<42:40, 1280.47s/it]  "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train_rmsle : 0.12772349  Test_rmsle : 0.6547555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 3/4 [33:34<15:38, 938.44s/it] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train_rmsle : 0.3652034464536798  Test_rmsle : 0.6837101870451242\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [40:21<00:00, 605.41s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train_rmsle : 0.29219528263101946  Test_rmsle : 0.6438341092410215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehE-lL2zdU3U",
        "outputId": "8e7bfe35-1643-4796-8a89-525b659cfecb"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "  \n",
        "# Specify the Column Names while initializing the Table\n",
        "myTable = PrettyTable([\"No of base_models\",\"Model\",\"Train RMSLE\",\"Test RMSLE\"])\n",
        "  \n",
        "# Add rows\n",
        "myTable.add_row([\"100\", \"RandomForestRegressor\", \"0.613\", \"0.77\"])\n",
        "myTable.add_row([\"100\", \"XGBRegressor\", \"0.163\", \"0.661\"])\n",
        "myTable.add_row([\"100\", \"CatBoostRegressor\", \"0.338\", \"0.683\"])\n",
        "myTable.add_row([\"100\", \"LGBMRegressor\", \"0.34\", \"0.663\"])\n",
        "myTable.add_row([\"300\", \"RandomForestRegressor\", \"0.573\", \"0.746\"])\n",
        "myTable.add_row([\"300\", \"XGBRegressor\", \"0.131\", \"0.644\"])\n",
        "myTable.add_row([\"300\", \"CatBoostRegressor\", \"0.376\", \"0.687\"])\n",
        "myTable.add_row([\"300\", \"LGBMRegressor\", \"0.301\", \"0.648\"])\n",
        "myTable.add_row([\"500\", \"RandomForestRegressor\", \"0.562\", \" 0.741\"])\n",
        "myTable.add_row([\"500\", \"XGBRegressor\", \"0.127\", \"0.654\"])\n",
        "myTable.add_row([\"500\", \"CatBoostRegressor\", \"0.365\", \"0.683\"])\n",
        "myTable.add_row([\"500\", \"LGBMRegressor\", \"0.292\", \"0.643\"])\n",
        "\n",
        "  \n",
        "print(myTable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+-----------------------+-------------+------------+\n",
            "| No of base_models |         Model         | Train RMSLE | Test RMSLE |\n",
            "+-------------------+-----------------------+-------------+------------+\n",
            "|        100        | RandomForestRegressor |    0.613    |    0.77    |\n",
            "|        100        |      XGBRegressor     |    0.163    |   0.661    |\n",
            "|        100        |   CatBoostRegressor   |    0.338    |   0.683    |\n",
            "|        100        |     LGBMRegressor     |     0.34    |   0.663    |\n",
            "|        300        | RandomForestRegressor |    0.573    |   0.746    |\n",
            "|        300        |      XGBRegressor     |    0.131    |   0.644    |\n",
            "|        300        |   CatBoostRegressor   |    0.376    |   0.687    |\n",
            "|        300        |     LGBMRegressor     |    0.301    |   0.648    |\n",
            "|        500        | RandomForestRegressor |    0.562    |    0.741   |\n",
            "|        500        |      XGBRegressor     |    0.127    |   0.654    |\n",
            "|        500        |   CatBoostRegressor   |    0.365    |   0.683    |\n",
            "|        500        |     LGBMRegressor     |    0.292    |   0.643    |\n",
            "+-------------------+-----------------------+-------------+------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilh2A2yTf5IJ"
      },
      "source": [
        "*  Base_models with 500 and LGBRegressor giving best results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr5htO87DMa9",
        "outputId": "7c727dc8-a6c5-44db-eff3-be1239036bcb"
      },
      "source": [
        "#hypertuning with best_model\n",
        "lgbm_clf = LGBMRegressor(tree_method='gpu_hist')\n",
        "params = {'n_estimators':[800,1200],\n",
        "        'learning_rate':[0.01,0.05,0.1],\n",
        "        'max_depth':[7,9,11],\n",
        "        'colsample_bytree':[0.8,0.9,1]}\n",
        "lgbm_model = RandomizedSearchCV(lgbm_clf,params,scoring='neg_root_mean_squared_error',n_jobs=-1,cv=3,verbose=10,random_state=0,n_iter=10)\n",
        "lgbm_model.fit(D2_pred,D2_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed: 13.9min\n",
            "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed: 19.5min\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 32.8min\n",
            "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed: 47.6min remaining:  5.3min\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 50.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=LGBMRegressor(boosting_type='gbdt',\n",
              "                                           class_weight=None,\n",
              "                                           colsample_bytree=1.0,\n",
              "                                           importance_type='split',\n",
              "                                           learning_rate=0.1, max_depth=-1,\n",
              "                                           min_child_samples=20,\n",
              "                                           min_child_weight=0.001,\n",
              "                                           min_split_gain=0.0, n_estimators=100,\n",
              "                                           n_jobs=-1, num_leaves=31,\n",
              "                                           objective=None, random_state=None,\n",
              "                                           reg_alpha=0.0, reg_lambda=0.0,\n",
              "                                           silen...\n",
              "                                           subsample_for_bin=200000,\n",
              "                                           subsample_freq=0,\n",
              "                                           tree_method='gpu_hist'),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
              "                   param_distributions={'colsample_bytree': [0.8, 0.9, 1],\n",
              "                                        'learning_rate': [0.01, 0.05, 0.1],\n",
              "                                        'max_depth': [7, 9, 11],\n",
              "                                        'n_estimators': [800, 1200]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
              "                   return_train_score=False,\n",
              "                   scoring='neg_root_mean_squared_error', verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkjVH6AZIL7k",
        "outputId": "991cf5aa-8639-4a07-f38f-72349c0dd9b3"
      },
      "source": [
        "lgbm_model.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': 0.9,\n",
              " 'learning_rate': 0.1,\n",
              " 'max_depth': 9,\n",
              " 'n_estimators': 1200}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsPEeBapIQLg",
        "outputId": "d90a57d1-b5dd-41a7-e01e-31bb7e44204a"
      },
      "source": [
        "lgbm_model.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.5594135231862865"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw17c_8lR9Fj"
      },
      "source": [
        "#training a metamodel with these 500 predictions using XGBRegressor\n",
        "lgbm = LGBMRegressor(n_estimators=1200,max_depth=9,learning_rate=0.1,colsample_bytree=0.9,tree_method='gpu_hist',reg='regression',verbosity=2,silent=True,n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE9MESRfpjdc",
        "outputId": "d52a2a30-fedd-403d-f0c9-90f7bfb71d8b"
      },
      "source": [
        "lgbm.fit(D2_pred, D2_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=0.9,\n",
              "              importance_type='split', learning_rate=0.1, max_depth=9,\n",
              "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "              n_estimators=1200, n_jobs=-1, num_leaves=31, objective=None,\n",
              "              random_state=None, reg='regression', reg_alpha=0.0,\n",
              "              reg_lambda=0.0, silent=True, subsample=1.0,\n",
              "              subsample_for_bin=200000, subsample_freq=0,\n",
              "              tree_method='gpu_hist', verbosity=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5_nb4Snps2Z"
      },
      "source": [
        "#final prediction will be get by passing the test data to 500 base models  and creating a 400 predictions of new dataset and then pass it to our metamodel.\n",
        "lgbm_pred_values = (lgbm.predict(test_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEnEnuS0mugX"
      },
      "source": [
        "## Training RMSLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsWJub3sqReO",
        "outputId": "bfb6cac6-f7c3-4192-fdee-1c0a04f1d5e8"
      },
      "source": [
        "print('Train RMSLE = ',np.sqrt(mean_squared_error((D2_y) ,(lgbm.predict(D2_pred)))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train RMSLE =  0.25164114338143234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi6ezy_Dm4LB"
      },
      "source": [
        "## Testing RMSLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pg0O5lQpqf73",
        "outputId": "2b8ea8c8-7dea-4cf0-851e-83c27d84a490"
      },
      "source": [
        "print('Test RMSLE = ',np.sqrt(mean_squared_error(test_y , lgbm_pred_values)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test RMSLE =  0.6775408288980387\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}